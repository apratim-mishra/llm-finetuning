# =============================================================================
# MLX SFT Configuration - Math Reasoning (Use Case 3)
# Model: Qwen2.5-7B-Instruct-4bit
# Note: Only SFT possible on Mac; DPO/GRPO requires cloud GPU
# =============================================================================

# Model Settings
model:
  name: "mlx-community/Qwen2.5-7B-Instruct-4bit"
  # ==========================================================================
  # Model Alternatives (uncomment to use)
  # ==========================================================================
  # Qwen3 (Latest - Recommended for Math)
  # name: "mlx-community/Qwen3-8B-Instruct-4bit"      # ~5GB, best reasoning
  # name: "mlx-community/Qwen3-4B-Instruct-4bit"      # ~3GB, fast iteration
  # name: "mlx-community/Qwen3-4B-Thinking-4bit"      # ~3GB, explicit CoT mode
  #
  # Gemma 3 (Google - Good math performance)
  # name: "mlx-community/gemma-3-4b-it-4bit"          # ~3GB, balanced
  # name: "mlx-community/gemma-3-12b-it-4bit"         # ~7GB, higher quality
  #
  # Llama 3.3 (Meta - Strong reasoning)
  # name: "mlx-community/Llama-3.3-8B-Instruct-4bit"  # ~5GB, reliable
  #
  # Legacy / Math-specific
  # name: "mlx-community/Qwen2.5-Math-7B-Instruct-4bit"
  # ==========================================================================
  max_seq_length: 2048 # Math needs longer context for reasoning

# LoRA Configuration
lora:
  rank: 64 # Higher rank for reasoning tasks
  alpha: 128
  dropout: 0.05
  layers: 16

# Training Settings
training:
  iters: 2000 # More iters for complex task
  batch_size: 1 # Longer sequences = smaller batch
  learning_rate: 1.0e-4 # Slightly higher for math
  warmup_steps: 100
  weight_decay: 0.01
  grad_checkpoint: true

# Validation
validation:
  val_batches: 50
  eval_every: 200

# Checkpointing
checkpoint:
  save_every: 500
  output_dir: "outputs/mlx/adapters/math_reasoning"

# Data Paths
data:
  train_file: "data/processed/math/sft_train.jsonl"
  val_file: "data/processed/math/sft_val.jsonl"

# Logging
logging:
  log_every: 20
  wandb:
    enabled: true
    project: "math-reasoning-mlx"
    run_name: "qwen2.5-7b-lora-math-sft"

# Evaluation (Mac-specific)
evaluation:
  # Run GSM8K subset during validation
  gsm8k_subset_size: 100
  extract_answer_pattern: "Answer:\\s*([0-9.,]+)"
