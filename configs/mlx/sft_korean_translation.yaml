# =============================================================================
# MLX SFT Configuration - Korean-English Translation (Use Case 1)
# Model: Qwen2.5-7B-Instruct-4bit (optimized for 24GB Mac)
# =============================================================================

# Model Settings
model:
  name: "mlx-community/Qwen2.5-7B-Instruct-4bit"
  # ==========================================================================
  # Model Alternatives (uncomment to use)
  # ==========================================================================
  # Qwen3 (Latest - Recommended)
  # name: "mlx-community/Qwen3-8B-Instruct-4bit"      # ~5GB, best quality
  # name: "mlx-community/Qwen3-4B-Instruct-4bit"      # ~3GB, fast iteration
  # name: "mlx-community/Qwen3-1.7B-Instruct-4bit"    # ~1.5GB, fastest
  #
  # Gemma 3 (Google - Multimodal capable)
  # name: "mlx-community/gemma-3-4b-it-4bit"          # ~3GB, good balance
  # name: "mlx-community/gemma-3-12b-it-4bit"         # ~7GB, higher quality
  #
  # Llama 3.3 (Meta - Strong baseline)
  # name: "mlx-community/Llama-3.3-8B-Instruct-4bit"  # ~5GB, reliable
  # name: "mlx-community/Llama-3.2-3B-Instruct-4bit"  # ~2GB, lightweight
  #
  # Legacy
  # name: "mlx-community/Phi-3.5-mini-instruct-4bit"  # ~2GB, fast iteration
  # ==========================================================================
  max_seq_length: 1024

# LoRA Configuration
lora:
  rank: 32 # Lower than GPU due to memory (GPU: 64)
  alpha: 64 # 2x rank
  dropout: 0.05
  layers: 16 # Number of transformer layers to apply LoRA
  # Target modules handled automatically by mlx-lm

# Training Settings
training:
  iters: 1000 # Validation run (GPU: 10000+)
  batch_size: 2 # Memory limited (GPU: 8+)
  learning_rate: 2.0e-5
  warmup_steps: 50
  weight_decay: 0.01
  grad_checkpoint: true # Essential for 24GB Mac

# Validation
validation:
  val_batches: 20
  eval_every: 100 # Evaluate every N iterations

# Checkpointing
checkpoint:
  save_every: 200
  output_dir: "outputs/mlx/adapters/korean_translation"

# Data Paths
data:
  train_file: "data/processed/korean_english/train.jsonl"
  val_file: "data/processed/korean_english/val.jsonl"
  test_file: "data/processed/korean_english/test.jsonl"

# Logging
logging:
  log_every: 10
  wandb:
    enabled: true
    project: "korean-translation-mlx"
    run_name: "qwen2.5-7b-lora-korean"
