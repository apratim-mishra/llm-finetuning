# GPU profile: NVIDIA H100 80GB (throughput-oriented defaults)
#
# Apply with:
#   python scripts/gpu/train_sft.py --config ... --profile configs/gpu/profiles/h100_80gb.yaml

model:
  torch_dtype: "bfloat16"
  attn_implementation: "flash_attention_2"

quantization:
  enabled: true
  bnb_4bit_compute_dtype: "bfloat16"

training:
  bf16: true
  fp16: false
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  dataloader_num_workers: 8

sft:
  packing: true

